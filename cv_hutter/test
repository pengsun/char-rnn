######################################################################
### gru
######################################################################
CUDA_VISIBLE_DEVICES=1 th test.lua cv_hutter/lm_gru_epoch50.00_1.2959.t7 -data_dir data/hutter -batch_size 500 -seq_length 100
using CUDA on GPU 0...	
loading data files...	
reshaping tensor...	
data load done. Number of data batches in train: 1900, val: 0, test: 100	
batch_size = 500	
vocab size: 205	
creating an gru...	
num_layers = 2	
rnn_size = 128	
number of parameters in the model: 254157	
cloning rnn	
cloning criterion	
warm up on training set...	
evaluating loss over split index 1	
 [=================== 1900/1900 ===============>] ETA: 0ms | Step: 495ms        
train loss = 1.2857298950396	
train bpc = 1.8549161434963	

	
evaluate on testing set...	
evaluating loss over split index 3	
 [=================== 100/100 =================>] ETA: 0ms | Step: 507ms        
test loss = 1.2937431457877	
test bpc = 1.866476820612	

######################################################################
### lstmlarge
######################################################################
CUDA_VISIBLE_DEVICES=1 th test.lua cv_hutter/lm_lstmlarge_epoch50.00_1.1391.t7 -data_dir data/hutter -batch_size 500 -seq_length 100
using CUDA on GPU 0...	
loading data files...	
reshaping tensor...	
data load done. Number of data batches in train: 1900, val: 0, test: 100	
batch_size = 500	
vocab size: 205	
creating an lstm...	
num_layers = 3	
rnn_size = 191	
number of parameters in the model: 930184	
cloning rnn	
cloning criterion	
warm up on training set...	
evaluating loss over split index 1	
 [=================== 1900/1900 ==============>] ETA: 0ms | Step: 545ms        
train loss = 1.1066296087632	
train bpc = 1.5965290486636	

	
evaluate on testing set...	
evaluating loss over split index 3	
 [=================== 100/100 ================>] ETA: 0ms | Step: 546ms        
test loss = 1.1254291080117	
test bpc = 1.6236509930006	

######################################################################
### lstmbig
######################################################################
CUDA_VISIBLE_DEVICES=0 th test.lua cv_hutter/lm_lstmbig_epoch50.00_1.1675.t7 -data_dir data/hutter -batch_size 500 -seq_length 100
using CUDA on GPU 0...	
loading data files...	
reshaping tensor...	
data load done. Number of data batches in train: 1900, val: 0, test: 100	
batch_size = 500	
vocab size: 205	
creating an lstm...	
num_layers = 2	
rnn_size = 192	
number of parameters in the model: 642445	
cloning rnn	
cloning criterion	
warm up on training set...	
evaluating loss over split index 1	
 [=================== 1900/1900 ==============>] ETA: 0ms | Step: 631ms        
train loss = 1.1443635690002	
train bpc = 1.6509676459706	

	
evaluate on testing set...	
evaluating loss over split index 3	
 [=================== 100/100 ================>] ETA: 0ms | Step: 633ms        
test loss = 1.1577470587492	
test bpc = 1.6702759402613	


######################################################################
### lstm
######################################################################
CUDA_VISIBLE_DEVICES=0 th test.lua cv_hutter/lm_lstm_epoch50.00_1.2562.t7 -data_dir data/hutter -batch_size 500 -seq_length 100
using CUDA on GPU 0...	
loading data files...	
reshaping tensor...	
data load done. Number of data batches in train: 1900, val: 0, test: 100	
batch_size = 500	
vocab size: 205	
creating an lstm...	
num_layers = 2	
rnn_size = 128	
number of parameters in the model: 330061	
cloning rnn	
cloning criterion	
warm up on training set...	
evaluating loss over split index 1	
 [=================== 1900/1900 ==============>] ETA: 0ms | Step: 240ms        
train loss = 1.2423691553931	
train bpc = 1.7923598194391	

	
evaluate on testing set...	
evaluating loss over split index 3	
 [=================== 100/100 ================>] ETA: 0ms | Step: 249ms        
test loss = 1.2535578347087	
test bpc = 1.8085016716017	
